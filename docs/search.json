[
  {
    "objectID": "workflow.html",
    "href": "workflow.html",
    "title": "Running Workflows on HPC",
    "section": "",
    "text": "Before you can execute workflows on Tower on Gadi, you will first need to run the tower agent. Navigate to the previously set up tower-nf directory on the command line and run the agent: \n\n\ncd /scratch/iz89/tower-nf \nbash run_tower_agent_pbs.sh\n\n\nBack at the tower interface, navigate to your launchpad or run on the command line and monitor on Tower:\nAll materials copyright Sydney Informatics Hub, University of Sydney"
  },
  {
    "objectID": "workflow.html#pawsey-setonix",
    "href": "workflow.html#pawsey-setonix",
    "title": "Running Workflows on HPC",
    "section": "Pawsey Setonix",
    "text": "Pawsey Setonix\nBefore you can execute workflows on Tower on Setonix, you will first need to run the tower agent.  Navigate to the previously set up tower-nf directory on the command line and run the agent: \n\n\ncd $MYSOFTWARE\nbash run_tower_agent_slurm.sh\n\n\nBack at the tower interface, navigate to your launchpad."
  },
  {
    "objectID": "setup_admin.html",
    "href": "setup_admin.html",
    "title": "Setup for the Admin Role",
    "section": "",
    "text": "Rather than the more common username and password style login you might be used to, NextFlow Tower uses an authentication link. To login:\n\n\n\nGo to https://tower.services.biocommons.org.au.\nProvide your University email address. ou will then receive an email with the access link in your email inbox. Click on this link to be logged into Nextflow Tower. Note that it can take a few minutes for the link to hit your inbox.\nAll materials copyright Sydney Informatics Hub, University of Sydney"
  },
  {
    "objectID": "setup_admin.html#the-interface",
    "href": "setup_admin.html#the-interface",
    "title": "Setup for the Admin Role",
    "section": "The interface",
    "text": "The interface\nUpon signing into Tower, you will be greeted with an interface for you as an individual user. To access the full functionality offered by the Australian BioCommons Tower service, you will need to move into (one of) your assigned BioCommons workspaces. To do this:\n\n\nSelect the dropdown menu by your user name.\nThen select the BioCommons workspace of interest.\n\n\nEach user has a unique personal workspace to manage resources such as pipelines, compute environments, and credentials. You can also create multiple workspaces within an organization context and associate each of these workspaces with dedicated teams of users, while providing a fine-grained access control model for each of the teams.\nThe Tower Dashboard provides an overview of runs in your organizations and personal workspace at a glance. Access it from the user top-right menu, under Dashboard. This is where you will manage your workspaces and workflows. It will open to the launchpad interface.\n\nAbove the interface you’ll see the following:\n\n\n\nLaunchpad: all your configured pipelines will be available here for running. Run them from here by selecting the ‘Launch’ button for the pipeline of interest. \nRuns: from here you can monitor and inspect the details of all previous workflow executions that you and other users in your workspace have run.\nActions: you can use Github and Tower webhooks to trigger an automated pipeline test run based on things like pipeline version release. \nDatasets: you can store pipeline input sample sheets here that specify metadata and file paths for each of your datapoints or samples to be processed by a workflow. \nCompute environment: Tower can be used to deploy workflows on various environments, here you will be able to manage and find your preconfigured environments. \nCredentials: here you can store all your authentication keys, credentials required to access private code repositories on GitHub, the Tower agent on HPCs, and external services. These are all encrypted, so they cannot be accessed by anyone else once you’ve stored them. \nSecrets: Ignore for now. \nParticipants: here you can see and manage (if you are an admin) the other users in your workspace and define user roles to control access. \nSettings: manage some basic workspace settings (if you are an admin)."
  },
  {
    "objectID": "setup_admin.html#setting-up-your-workspace",
    "href": "setup_admin.html#setting-up-your-workspace",
    "title": "Setup for the Admin Role",
    "section": "Setting up your workspace",
    "text": "Setting up your workspace\nWorkspace configuration can only be performed by admins. With workspace configuration, you can create and configure compute environments, configure workflows to run on these environments, and add collaborators. The NeuroCommunity are currently only trialling the Tower service at NCI Gadi and Pawsey Setonix HPCs. As such, you will need to create Tower Agent credentials because this is the only way to access NCI and Pawsey HPC’s with Tower.\n\nCreate your personal access token\nYou will need to create a personal access token and store it on your compute environment (i.e. on the HPC environment, not locally) in order to communicate with the Tower API. To create a personal access token you will need to navigate to the user settings logo in the top navbar and select ‘Your tokens’, then:\n\n\nSelect ‘Add Token’. \nName your token something descriptive and select ‘Add’.\n\nCopy the token to your clipboard.\n\nLog in to your HPC (either NCI Gadi or Pawsey Setonix) on the command-line.\n\nIf you are using Gadi, navigate to $HOME.\nIf you are on Setonix, navigate to $MYSOFTWARE.\n\nFrom within the directory mentioned above, make a hidden directory called tower to store Tower token and credentials in.\nCopy your personal access token into a file named token within this directory.\n\n\n\n\n\nCreate a Tower credential for your HPC\nYou can create different types of credentials for different purposes through the Tower interface. For example, you can add credentials to access code repositories, commercial cloud, SSH-keys, and the Tower Agent. To connect your Tower agent to your HPC, you will need to create a Tower agent personal credential.\n\nTo set up your Tower agent credential, you will need to navigate to the user settings logo in the top navbar and select ‘Your credentials’.  \nYou can either choose to work with a shared or personal credential. Setting this up requires a similar process to creating a personal access token, using both the command line and Tower interface. Starting on the Tower interface, navigate to ‘Credentials’ in the top navbar menu:\n\n\n\nSelect ‘Add Credential’.\nName the credential something descriptive.\nSelect Tower Agent from the Provider dropdown menu.\nEnable ‘Shared agent’ so that all workspace users can access the same instance (optional).\nCopy the Agent connection ID to your clipboard.\n\nBefore saving the credential you will need to run the agent on your HPC command line. \nLog in to your HPC project space on the command-line and navigate to the shared space where you’ll be running the tower agent from. \nCopy your personal access token into a file named connection_id within the hidden .tower directory.\n\nNavigate to your working directory (not $HOME).\n\nOn gadi, run the run_tower_agent_pbs.sh script at /g/data/er01/tower-nf.\n\nOn setonix, TBA.\n\nBack in the tower interface, hit ‘Add’ to save your Tower agent credential.\nYou can cancel the Tower agent running on the command line after the credential is saved.\n\n\n\n\nConfigure a compute environment \nCompute environments have been configured for our group on NCI Gadi and Pawsey Setonix HPCs. The process for setting up this workspace is as follows:\n\n\nRun the tower agent on the HPC command line again with the relevant run_tower_agent_<pbs|slurm>.sh script\nIn the Tower interface, navigate to ‘Compute Environments’ in the top navbar menu.\nName the environment something descriptive to distinguish it from other environments you may set up.\nSelect the platform. For Setonix this is Slurm workload manager, for Gadi this is Altair PBS Pro. \nProvide your (shared or personal) credentials previously saved to the connection_id file.\n\n\n\n\nNCI Gadi HPC\nCurrently only NCI Gadi is a shared environment. The NCI Gadi environment has specifically been configured for our SIH project ‘er01’. Only users with access to er01 added to our workspace will be able to run workflows using this configured compute environment. It’s important that you leave the head and compute queue names empty, given jobs submitted to queues on Gadi are transferred to the exec version of each queue once running. The exec queue names are not visible to the Tower API so your jobs will fail to run. \n\n\nUnder Staging options:\n\nmodule load nextflow/23.04.1.\nmodule load singularity/3.8.6-nompi.\n\nUnder Advanced options:\n\nNextflow queue size: Set to 1000 (as directed here).\nHead job options: PBS options and applied head jobs to the compute jobs. Add queue as “copyq” to provide external network access.\n\n--Iwalltime=10:00:00, ncpus=1, mem=8G, storage=scratch/<project>+gdata/<project>, wd -P <project> -q copyq\n\n\n\n\n\n\n\nPawsey Setonix HPC\n\n\nWork directory: $TW_AGENT_WORK.\nLaunch directory: should be in the /scratch partition, because this is where you should run workflows. For example, /scratch/project_id/user_id/sv_calling.\nHead queue name: work.\nCompute queue name: work, unless you have a specific reason to select the long, highmem, or copy queue due to your workflow requirements.\nUnder Staging options:\n\nPre-run script: Here we load the needed system modules for running a Nextflow tower job. This currently includes the following modules, but the specific versions may change over time. You can check on the Setonix command line which module versions are available\n\nmodule load nextflow/23.04.1 \nmodule load singularity/3.8.6-nompi\n\n\nUnder Advanced options:\n\nNextflow queue size: Set to 1024.\nHead job submit options: This setting provides resources specifications for running the Nextflow head job. The main parameter you might want to change is `time`. You may need less than 24 hours walltime, in which case you can reduce the requested time.\n\n--time=24:00:00 --ntasks=1 --tasks-per-node=1 --mem=12G --cpus-per-task=1"
  },
  {
    "objectID": "setup_admin.html#adding-collaborators",
    "href": "setup_admin.html#adding-collaborators",
    "title": "Setup for the Admin Role",
    "section": "Adding collaborators",
    "text": "Adding collaborators\nCollaborators are users who are invited to an organizations workspace, but are not members of that organization. As a result, their access is limited to only within that workspace. New collaborators to an organization’s workspace can be added using the Participants.\n\nTo create a new team within an organization:\n\nGo to the Participants tab of the organization menu.\nClick on Add participant.\nEnter the Name of new participant. \nOptionally, update the role associated with the participant of the organization members or collaborators.\n\n\nThere are five roles available for every workspace participant:\n\n\nOwner: The participant have full permissions on any resources within the workspace, including the workspace settings.\nAdmin: The participant have full permission on the resources associated with the workspace. Therefore they can create/modify/delete Pipelines, Compute environments, Actions and Credentials. They can add/remove users to the workspace, but cannot access the workspace settings.\nMaintain: The participant can launch pipelines and modify pipeline executions (e.g. can change the pipeline launch compute environments, parameters, pre/post-run scripts and nextflow configuration) and create new pipelines in the Launchpad. The users cannot modify Compute Environments and Credentials.\nLaunch: The participant can launch pipelines and modify the pipeline input/output parameters in the Launchpad. They cannot modify the launch configuration and other resources.\nView: The participant can view the team pipelines and runs in read-only mode."
  },
  {
    "objectID": "pipeline.html",
    "href": "pipeline.html",
    "title": "Adding General and NF-CORE Pipelines",
    "section": "",
    "text": "A simple script showing the basic Hello World! example for the Nextflow framework.\n\n\n\n\nFrom the Launchpad, select “Add pipeline”. \nGive your pipeline a descriptive name. It needs to be unique to your community (can’t create one that already exists in broader BioCommons group). \nSelect your previously configured compute environment.\nProvide pipeline codebase URL https://github.com/nextflow-io/hello.\nSelect main for the Revision number.\nSpecify $TW_AGENT_WORK for the work directory.\nSelect either gadi or setonix for the config profiles (these are provided in the code base of the workflow).\nSelect “Add”.\nAll materials copyright Sydney Informatics Hub, University of Sydney"
  },
  {
    "objectID": "pipeline.html#nf-core",
    "href": "pipeline.html#nf-core",
    "title": "Adding General and NF-CORE Pipelines",
    "section": "NF-CORE",
    "text": "NF-CORE\nnf-core is a community effort to collect a curated set of analysis pipelines built using Nextflow. It has three target audiences: facilities, single users, and developers. For facilities, it provides highly automated and optimised pipelines that guarantee reproducibility of results for their users. Single users profit from portable, documented, and easy-to-use workflows. However, you can also become a developer and write your own pipelines in Nextflow using ready-made templates and helper tools.\n\nCurrently, there are 86 pipelines available, below are a few examples:\n\nGermline-StructuralV\nGermlineStructuralV-nf is a pipeline for identifying structural variant events in human Illumina short read whole genome sequence data. GermlineStructuralV-nf identifies structural variant and copy number events from BAM files using Manta, Smoove, and TIDDIT. Variants are then merged using SURVIVOR, and annotated by AnnotSV. The pipeline is written in Nextflow and uses Singularity/Docker to run containerised tools.\nStructural and copy number detection is challenging. Most structural variant detection tools infer these events from read mapping patterns, which can often resemble sequencing and read alignment artefacts. To address this, GermlineStructuralV-nf employs 3 general purpose structural variant calling tools, which each support a combination of detection methods. Manta, Smoove and TIDDIT use typical detection approaches that consider:\n\n\nDiscordant read pair alignments\nSplit reads that span a breakpoints\nRead depth profiling\nLocal de novo assembly\n\n\nThis approach is currently considered the best approach for maximising sensitivty of short read data (Cameron et al. 2019, Malmoud et al. 2019). By using a combination of tools that employ different methods, we improve our ability to detect different types and sizes of variant events.\n\n\n\nFrom the Launchpad, select “Add pipeline”. \nGive your pipeline a descriptive name. It needs to be unique to your community (can’t create one that already exists in broader BioCommons group). \nSelect your previously configured compute environment.\nProvide pipeline codebase URL https://github.com/Sydney-Informatics-Hub/Germline-StructuralV-nf. \nSelect main for the Revision number.\nSpecify $TW_AGENT_WORK for the work directory.\nSelect either gadi or setonix for the config profiles (these are provided in the code base of the workflow).\nSelect “Add”.\n\n\n\n\n\nAmpliseq\nnfcore/ampliseq is a bioinformatics analysis pipeline used for amplicon sequencing, supporting denoising of any amplicon and, currently, taxonomic assignment of 16S, ITS, CO1 and 18S amplicons. Phylogenetic placement is also possible. Supported is paired-end Illumina or single-end Illumina, PacBio and IonTorrent data. Default is the analysis of 16S rRNA gene amplicons sequenced paired-end with Illumina.\n\n\n\nFrom the Launchpad, select “Add pipeline”. \nGive your pipeline a descriptive name. It needs to be unique to your community (can’t create one that already exists in broader BioCommons group). \nSelect your previously configured compute environment.\nProvide pipeline codebase URL https://github.com/nf-core/ampliseq/tree/2.6.1.\nSelect 2.6.1 for the Revision number.\nSpecify $TW_AGENT_WORK for the work directory.\nSelect either gadi or setonix for the config profiles (these are provided in the code base of the workflow).\nSelect “Add”.\n\n\n\n\nRNAseq\nnf-core/rnaseq is a bioinformatics pipeline that can be used to analyse RNA sequencing data obtained from organisms with a reference genome and annotation. It takes a samplesheet and FASTQ files as input, performs quality control (QC), trimming and (pseudo-)alignment, and produces a gene expression matrix and extensive QC report.\n\n\n\nFrom the Launchpad, select “Add pipeline”. \nGive your pipeline a descriptive name. It needs to be unique to your community (can’t create one that already exists in broader BioCommons group). \nSelect your previously configured compute environment.\nProvide pipeline codebase URL https://github.com/nf-core/rnaseq.\nSelect Master for the Revision number.\nSpecify $TW_AGENT_WORK for the work directory.\nSelect either gadi or setonix for the config profiles (these are provided in the code base of the workflow).\nSelect “Add”."
  },
  {
    "objectID": "pipeline.html#configured-launchpad",
    "href": "pipeline.html#configured-launchpad",
    "title": "Adding General and NF-CORE Pipelines",
    "section": "Configured Launchpad",
    "text": "Configured Launchpad\nYour launchpad will now reload with a preconfigured workflows."
  },
  {
    "objectID": "setup_participant.html",
    "href": "setup_participant.html",
    "title": "Setup for the Launch Role",
    "section": "",
    "text": "Rather than the more common username and password style login you might be used to, NextFlow Tower uses an authentication link. To login:\n\n\n\nGo to https://tower.services.biocommons.org.au.\nProvide your University email address. ou will then receive an email with the access link in your email inbox. Click on this link to be logged into Nextflow Tower. Note that it can take a few minutes for the link to hit your inbox.\nAll materials copyright Sydney Informatics Hub, University of Sydney"
  },
  {
    "objectID": "setup_participant.html#the-interface",
    "href": "setup_participant.html#the-interface",
    "title": "Setup for the Launch Role",
    "section": "The interface",
    "text": "The interface\nUpon signing into Tower, you will be greeted with an interface for you as an individual user. To access the full functionality offered by the Australian BioCommons Tower service, you will need to move into (one of) your assigned BioCommons workspaces. To do this:\n\n\nSelect the dropdown menu by your user name.\nThen select the BioCommons workspace of interest.\n\n\nEach user has a unique personal workspace to manage resources such as pipelines, compute environments, and credentials. You can also create multiple workspaces within an organization context and associate each of these workspaces with dedicated teams of users, while providing a fine-grained access control model for each of the teams.\nThe Tower Dashboard provides an overview of runs in your organizations and personal workspace at a glance. Access it from the user top-right menu, under Dashboard. This is where you will manage your workspaces and workflows. It will open to the launchpad interface.\n\nAbove the interface you’ll see the following:\n\n\n\nLaunchpad: all your configured pipelines will be available here for running. Run them from here by selecting the ‘Launch’ button for the pipeline of interest. \nRuns: from here you can monitor and inspect the details of all previous workflow executions that you and other users in your workspace have run.\nActions: you can use Github and Tower webhooks to trigger an automated pipeline test run based on things like pipeline version release. \nDatasets: you can store pipeline input sample sheets here that specify metadata and file paths for each of your datapoints or samples to be processed by a workflow. \nCompute environment: Tower can be used to deploy workflows on various environments, here you will be able to manage and find your preconfigured environments. \nCredentials: here you can store all your authentication keys, credentials required to access private code repositories on GitHub, the Tower agent on HPCs, and external services. These are all encrypted, so they cannot be accessed by anyone else once you’ve stored them. \nSecrets: Ignore for now. \nParticipants: here you can see and manage (if you are an admin) the other users in your workspace and define user roles to control access. \nSettings: manage some basic workspace settings (if you are an admin)."
  },
  {
    "objectID": "setup_participant.html#create-your-personal-access-token",
    "href": "setup_participant.html#create-your-personal-access-token",
    "title": "Setup for the Launch Role",
    "section": "Create your personal access token",
    "text": "Create your personal access token\nWorkspace configuration can only be performed by admins but you will still need to create a personal access token and store it on your compute environment (i.e. on the HPC environment, not locally) in order to communicate with the Tower API. To create a personal access token you will need to navigate to the user settings logo in the top navbar and select ‘Your tokens’, then:\n\n\nSelect ‘Add Token’. \nName your token something descriptive and select ‘Add’.\n\nCopy the token to your clipboard.\n\nLog in to your HPC (either NCI Gadi or Pawsey Setonix) on the command-line.\n\nIf you are using Gadi, navigate to $HOME.\nIf you are on Setonix, navigate to $MYSOFTWARE.\n\nFrom within the directory mentioned above, make a hidden directory called tower to store Tower token and credentials in.\nCopy your personal access token into a file named token within this directory."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Nextflow Tower User Guide for University of Sydney",
    "section": "",
    "text": "Nextflow Tower is a full-stack solution for the management of Nextflow pipeline executions. It’s designed as an intuitive, user-friendly interface that allows you to control and monitor your data analysis pipelines. It simplifies running complex workflows, like those provided by nf-core, on different computation infrastructures such as HPC clusters, cloud services, or Kubernetes."
  },
  {
    "objectID": "index.html#resources",
    "href": "index.html#resources",
    "title": "Nextflow Tower User Guide for University of Sydney",
    "section": "Resources",
    "text": "Resources\n\nAustralian Biocommons tower service\nAustralian Biocommons tower user guide\nTower-nf HPC configuration scripts"
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "Nextflow Tower User Guide for University of Sydney",
    "section": "Getting started",
    "text": "Getting started\nThe Tower service is offered in two ways:\n\nA free basic account that can be used by individuals\nA licensed service that is suitable for large organisations with multiple collaborators that require more complex user management.\n\nThe Australian BioCommons Nextflow Tower service is licensed and provides a centralised command-post for running Nextflow pipelines as a subsidised service for Australian researchers. More information on workspace management can be found here: workspace management.\n\n\n\n\n\n\nEssential consideration for using the service\n\n\n\n\nThis service provides an interface for managing users, compute environments, and workflows within defined spaces called workspaces\nWorkspaces are provided by the Australian BioCommons to use cases for the pilot program of the Australian BioCommons Nextflow Tower service\nThe Australian BioCommons service team has insight into and administrative control over workspaces\nWorkspace management and curation is the responsibility of the workspace administrator(s) from the research group.\nOnly organisation owners are permitted to create a workspace within the organisation.\n\n\n\n\nOrganisational workspace set up\nA workspace provides the context in which a user operates, including what resources are available and who can access them. It is composed of pipelines, compute environments, credentials, runs, actions, and datasets. Access permissions are controlled through participants, collaborators, and teams \n\n\n\n\n\n\n\nLevel\nDefinition\n\n\n\n\nOrganisation\nTop-level entity where businesses, institutions, and groups can collaborate. It can contain multiple workspaces.\n\n\nTeam\nGroup of members in the same organization. Teams can operate in one or more organization workspaces with a specific workspace role (one role per workspace).\n\n\nParticipant\nA user operating with an assigned role within a workspace. Participants can be assigned different levels of access within a workspace."
  },
  {
    "objectID": "index.html#glossary-of-terms",
    "href": "index.html#glossary-of-terms",
    "title": "Nextflow Tower User Guide for University of Sydney",
    "section": "Glossary of terms",
    "text": "Glossary of terms\nAs you use Tower, keep in mind there are a number of key terms and core concepts that you will come across as you set up your workspace, configure your compute environments, and execute your workflows. \n\n\n\n\n\n\n\n\nDefinition\n\n\n\n\nActions\nActions are used to automate the execution of pre-configured workflows (pipelines), based on event triggers such as code commits and webhooks.\n\n\nCache\nA feature that allows Nextflow to store and reuse previously computed results to avoid redundant computations.\n\n\nCluster\nA network of computers or servers used for distributed computing and task execution.\n\n\nCompute Environments\nA compute environment is the platform where workflows are executed. It is composed of access credentials, configuration settings, and storage options for the environment.\n\n\nConfiguration File\nA file containing settings and parameters that control how a Nextflow workflow is executed.\n\n\nCredentials\nCredentials are access keys stored by Tower in an encrypted format, using AES-256 encryption. They allow the safe storage of authentication keys for compute environments, private code repositories, and external services.\n\n\nDatasets\nDatasets are collections of versioned, structured data, usually in TSV (tab-separated values) and CSV (comma-separated values) formats. They are used to manage sample sheets and metadata, to be validated and used as inputs for workflow executions.\n\n\nGitHub/GitLab\nVersion control platforms used to manage and collaborate on Nextflow workflow scripts and associated files.\n\n\nLaunchpad\nThe Launchpad contains the collection of available pipelines that can be run in a workspace. From here, you can view and select pre-configured pipelines for launch.\n\n\nMembers\nA member is a user who is internal to the organization. Members have an organization role and can operate in one or more organization workspaces. In each workspace, members can have a participant role that defines the permissions granted to them within that workspace.\n\n\nPipeline\nA pipeline is a pre-configured workflow that can be used by all users in a workspace. It is composed of a workflow repository, launch parameters, and a compute environment.\n\n\nPipeline Secrets\nPipeline secrets are keys used by workflow tasks to interact with external systems, such as a password to connect to an external database or an API token. They are stored in Tower using AES-256 encryption.\n\n\nRun\nA run is a workflow execution. The Runs view is used to monitor and inspect the details of workflow executions in a workspace.\n\n\nShared Environment\nCould refer to a cluster, cloud computing environment, or High-Performance Computing (HPC) system where different users or workflows share the available resources for task execution.\n\n\nTask\nA single unit of work within a workflow. It typically represents a specific analysis step, such as aligning sequences, running statistical analyses, or generating plots.\n\n\nWorkflow\nA sequence of tasks or processes arranged in a specific order to achieve a specific goal, often in the context of scientific or data analysis tasks.\n\n\nWorkspace\nA workspace provides the context in which a user operates, including what resources are available and who can access them. It is composed of pipelines, compute environments, credentials, runs, actions, and datasets. Access permissions are controlled through participants, collaborators, and teams."
  },
  {
    "objectID": "hpc.html",
    "href": "hpc.html",
    "title": "HPC Access",
    "section": "",
    "text": "NCI is a research-focused organization that provides advanced computing, data storage, and data management solutions to support scientific research and innovation in Australia and beyond. NCI’s HPC systems are designed to handle complex computational tasks, such as simulations, data analysis, and modeling, for a wide range of scientific disciplines, including climate modeling, genomics, astronomy, and materials science."
  },
  {
    "objectID": "hpc.html#resources",
    "href": "hpc.html#resources",
    "title": "HPC Access",
    "section": "Resources",
    "text": "Resources\n\nNCI help"
  },
  {
    "objectID": "hpc.html#setting-up-your-nci-account",
    "href": "hpc.html#setting-up-your-nci-account",
    "title": "HPC Access",
    "section": "Setting up your NCI Account",
    "text": "Setting up your NCI Account\nAll new users must create their account through the NCI online self service portal.\n\nTo create your account you will need the following information:\n\nYour Name\nInstitutional email address (Gmail, Hotmail, etc are not accepted)\nMobile phone number (optional, but strongly encouraged as you otherwise won’t be able to easily reset your password)\nEither:\n\nNCI project code of an existing project you wish to join\nA new project proposal to be assessed by a Scheme Manager to determine if they will grant your project time\n\n\n\nNote that resources at NCI are allocated to projects and not to individual users.\n\n\n\nClick on the Sign up here link to start your registration form.\n\n\nComplete all steps in the registration form.\n\n\n\n\nYour username will become active when a project Lead CI approves your request to join their project, or when a Scheme Manager approves your new project proposal. You will receive a confirmation email from the Mancini system when your username is activated."
  },
  {
    "objectID": "hpc.html#how-to-log-into-gadi",
    "href": "hpc.html#how-to-log-into-gadi",
    "title": "HPC Access",
    "section": "How to log into Gadi",
    "text": "How to log into Gadi\n\nLinux/Mac/Unix\nAccess to Gadi is via SSH to gadi.nci.org.au. This provides a Unix shell on one of the Gadi login nodes.\n\n\n\nReplace abc123 with your own username. Enter your password when prompted. If you can’t remember your password, you can reset it via Mancini.\n\n\n\nCopying Files\nTo copy files to Gadi you should use the Gadi data movers gadi-dm.nci.org.au:\n\n\n\n\nX11 (X-Windows)\n\n\n\nWhen using OS X 10.8 or later you will need to install XQuartz from https://www.xquartz.org before you can use X11 on a Mac.\n\n\n\nCopying Files\nWe recommend the use of one of the following packages for X11 access to Gadi:\n\n\nMobaXterm from http://mobaxterm.mobatek.net\nCygwin from https://cygwin.com\nXming from http://www.straightrunning.com/XmingNotes/\n\n\n\n\n\nWindows\n\n\n\n\n\nCopying Files\nTo copy files to Gadi you should use the Gadi data movers gadi-dm.nci.org.au:\nWe recommend the following applications to copy files to and from Gadi:\n\n\nMobaXterm from http://mobaxterm.mobatek.net\nPuTTY’s PSCP or PSFTP applications from http://www.chiark.greenend.org.uk/~sgtatham/putty/\nFileZilla from https://filezilla-project.org\nWinSCP from https://winscp.net/\n\n\nTo transfer files/folders using MobaXterm on Windows system, drag and drop files/folders to/from local computer and Gadi after log in to Gadi via MobaXterm."
  },
  {
    "objectID": "notebooks/setup_participant.html",
    "href": "notebooks/setup_participant.html",
    "title": "Setup for the Launch Role",
    "section": "",
    "text": "Workspace configuration can only be performed by admins but you will still need to create a personal access token and store it on your compute environment (i.e. on the HPC environment, not locally) in order to communicate with the Tower API. To create a personal access token you will need to navigate to the user settings logo in the top navbar and select ‘Your tokens’, then:\n\nSelect ‘Add Token’. \nName your token something descriptive and select ‘Add’: \nCopy the token to your clipboard: \nOpen your terminal application, log in to your HPC (either NCI Gadi or Pawsey Setonix) on the command-line:\n\nssh abc123@gadi.nci.org.au\n\nIf you are using Gadi, navigate to ~ ($HOME):\n\ncd ~\n\nIf you are on Setonix, navigate to $MYSOFTWARE:\n\ncd $MYSOFTWARE\n\nFrom within the directory mentioned above, make a hidden tower (.tower) directory to store Tower token and credentials:\n\nmkdir .tower\n\nCopy your personal access token into a file named token within this directory:"
  },
  {
    "objectID": "notebooks/setup_participant.html#the-interface",
    "href": "notebooks/setup_participant.html#the-interface",
    "title": "Setup for the Launch Role",
    "section": "The interface",
    "text": "The interface\nUpon signing into Tower, you will be greeted with an interface for you as an individual user. To access the full functionality offered by the Australian BioCommons Tower service, you will need to move into (one of) your assigned BioCommons workspaces. To do this:\n\n\nSelect the dropdown menu by your user name.\nThen select the BioCommons workspace of interest.\n\n\nEach user has a unique personal workspace to manage resources such as pipelines, compute environments, and credentials. You can also create multiple workspaces within an organization context and associate each of these workspaces with dedicated teams of users, while providing a fine-grained access control model for each of the teams.\nThe Tower Dashboard provides an overview of runs in your organizations and personal workspace at a glance. Access it from the user top-right menu, under Dashboard. This is where you will manage your workspaces and workflows. It will open to the launchpad interface.\n\nAbove the interface you’ll see the following:\n\n\n\nLaunchpad: all your configured pipelines will be available here for running. Run them from here by selecting the ‘Launch’ button for the pipeline of interest. \nRuns: from here you can monitor and inspect the details of all previous workflow executions that you and other users in your workspace have run.\nActions: you can use Github and Tower webhooks to trigger an automated pipeline test run based on things like pipeline version release. \nDatasets: you can store pipeline input sample sheets here that specify metadata and file paths for each of your datapoints or samples to be processed by a workflow. \nCompute environment: Tower can be used to deploy workflows on various environments, here you will be able to manage and find your preconfigured environments. \nCredentials: here you can store all your authentication keys, credentials required to access private code repositories on GitHub, the Tower agent on HPCs, and external services. These are all encrypted, so they cannot be accessed by anyone else once you’ve stored them. \nSecrets: Ignore for now. \nParticipants: here you can see and manage (if you are an admin) the other users in your workspace and define user roles to control access. \nSettings: manage some basic workspace settings (if you are an admin)."
  },
  {
    "objectID": "notebooks/setup_participant.html#create-your-personal-access-token",
    "href": "notebooks/setup_participant.html#create-your-personal-access-token",
    "title": "Setup for the Launch Role",
    "section": "Create your personal access token",
    "text": "Create your personal access token\nWorkspace configuration can only be performed by admins but you will still need to create a personal access token and store it on your compute environment (i.e. on the HPC environment, not locally) in order to communicate with the Tower API. To create a personal access token you will need to navigate to the user settings logo in the top navbar and select ‘Your tokens’, then:\n\n\nSelect ‘Add Token’. \nName your token something descriptive and select ‘Add’.\n\nCopy the token to your clipboard.\n\nLog in to your HPC (either NCI Gadi or Pawsey Setonix) on the command-line.\n\nIf you are using Gadi, navigate to $HOME.\nIf you are on Setonix, navigate to $MYSOFTWARE.\n\nFrom within the directory mentioned above, make a hidden directory called tower to store Tower token and credentials in.\nCopy your personal access token into a file named token within this directory."
  },
  {
    "objectID": "notebooks/pipeline.html",
    "href": "notebooks/pipeline.html",
    "title": "Adding General and NF-CORE Pipelines",
    "section": "",
    "text": "A simple script showing the basic Hello World! example for the Nextflow framework.\n\n\n\n\nFrom the Launchpad, select “Add pipeline”. \nGive your pipeline a descriptive name. It needs to be unique to your community (can’t create one that already exists in broader BioCommons group). \nSelect your previously configured compute environment.\nProvide pipeline codebase URL https://github.com/nextflow-io/hello.\nSelect main for the Revision number.\nSpecify $TW_AGENT_WORK for the work directory.\nSelect either gadi or setonix for the config profiles (these are provided in the code base of the workflow).\nSelect “Add”."
  },
  {
    "objectID": "notebooks/pipeline.html#nf-core",
    "href": "notebooks/pipeline.html#nf-core",
    "title": "Adding General and NF-CORE Pipelines",
    "section": "NF-CORE",
    "text": "NF-CORE\nnf-core is a community effort to collect a curated set of analysis pipelines built using Nextflow. It has three target audiences: facilities, single users, and developers. For facilities, it provides highly automated and optimised pipelines that guarantee reproducibility of results for their users. Single users profit from portable, documented, and easy-to-use workflows. However, you can also become a developer and write your own pipelines in Nextflow using ready-made templates and helper tools.\n\nCurrently, there are 86 pipelines available, below are a few examples:\n\nGermline-StructuralV\nGermlineStructuralV-nf is a pipeline for identifying structural variant events in human Illumina short read whole genome sequence data. GermlineStructuralV-nf identifies structural variant and copy number events from BAM files using Manta, Smoove, and TIDDIT. Variants are then merged using SURVIVOR, and annotated by AnnotSV. The pipeline is written in Nextflow and uses Singularity/Docker to run containerised tools.\nStructural and copy number detection is challenging. Most structural variant detection tools infer these events from read mapping patterns, which can often resemble sequencing and read alignment artefacts. To address this, GermlineStructuralV-nf employs 3 general purpose structural variant calling tools, which each support a combination of detection methods. Manta, Smoove and TIDDIT use typical detection approaches that consider:\n\n\nDiscordant read pair alignments\nSplit reads that span a breakpoints\nRead depth profiling\nLocal de novo assembly\n\n\nThis approach is currently considered the best approach for maximising sensitivty of short read data (Cameron et al. 2019, Malmoud et al. 2019). By using a combination of tools that employ different methods, we improve our ability to detect different types and sizes of variant events.\n\n\n\nFrom the Launchpad, select “Add pipeline”. \nGive your pipeline a descriptive name. It needs to be unique to your community (can’t create one that already exists in broader BioCommons group). \nSelect your previously configured compute environment.\nProvide pipeline codebase URL https://github.com/Sydney-Informatics-Hub/Germline-StructuralV-nf. \nSelect main for the Revision number.\nSpecify $TW_AGENT_WORK for the work directory.\nSelect either gadi or setonix for the config profiles (these are provided in the code base of the workflow).\nSelect “Add”.\n\n\n\n\n\nAmpliseq\nnfcore/ampliseq is a bioinformatics analysis pipeline used for amplicon sequencing, supporting denoising of any amplicon and, currently, taxonomic assignment of 16S, ITS, CO1 and 18S amplicons. Phylogenetic placement is also possible. Supported is paired-end Illumina or single-end Illumina, PacBio and IonTorrent data. Default is the analysis of 16S rRNA gene amplicons sequenced paired-end with Illumina.\n\n\n\nFrom the Launchpad, select “Add pipeline”. \nGive your pipeline a descriptive name. It needs to be unique to your community (can’t create one that already exists in broader BioCommons group). \nSelect your previously configured compute environment.\nProvide pipeline codebase URL https://github.com/nf-core/ampliseq/tree/2.6.1.\nSelect 2.6.1 for the Revision number.\nSpecify $TW_AGENT_WORK for the work directory.\nSelect either gadi or setonix for the config profiles (these are provided in the code base of the workflow).\nSelect “Add”.\n\n\n\n\nRNAseq\nnf-core/rnaseq is a bioinformatics pipeline that can be used to analyse RNA sequencing data obtained from organisms with a reference genome and annotation. It takes a samplesheet and FASTQ files as input, performs quality control (QC), trimming and (pseudo-)alignment, and produces a gene expression matrix and extensive QC report.\n\n\n\nFrom the Launchpad, select “Add pipeline”. \nGive your pipeline a descriptive name. It needs to be unique to your community (can’t create one that already exists in broader BioCommons group). \nSelect your previously configured compute environment.\nProvide pipeline codebase URL https://github.com/nf-core/rnaseq.\nSelect Master for the Revision number.\nSpecify $TW_AGENT_WORK for the work directory.\nSelect either gadi or setonix for the config profiles (these are provided in the code base of the workflow).\nSelect “Add”."
  },
  {
    "objectID": "notebooks/pipeline.html#configured-launchpad",
    "href": "notebooks/pipeline.html#configured-launchpad",
    "title": "Adding General and NF-CORE Pipelines",
    "section": "Configured Launchpad",
    "text": "Configured Launchpad\nYour launchpad will now reload with a preconfigured workflows."
  },
  {
    "objectID": "notebooks/hpc.html",
    "href": "notebooks/hpc.html",
    "title": "Accessing NCI Gadi HPC",
    "section": "",
    "text": "NCI is a research-focused organisation that provides advanced computing, data storage, and data management solutions to support scientific research and innovation in Australia and beyond. NCI’s HPC systems are designed to handle complex computational tasks, such as simulations, data analysis, and modeling, for a wide range of scientific disciplines, including climate modeling, genomics, astronomy, and materials science. The University of Sydney provides its researchers with subsidised access to NCI’s infrastructure."
  },
  {
    "objectID": "notebooks/hpc.html#resources",
    "href": "notebooks/hpc.html#resources",
    "title": "Accessing NCI Gadi HPC",
    "section": "Resources",
    "text": "Resources\n\nNCI help"
  },
  {
    "objectID": "notebooks/hpc.html#setting-up-your-nci-account",
    "href": "notebooks/hpc.html#setting-up-your-nci-account",
    "title": "Accessing NCI Gadi HPC",
    "section": "Setting up your NCI Account",
    "text": "Setting up your NCI Account\nAll new users must create their account through the NCI online self service portal.\n\nTo create your account you will need the following information:\n\nYour Name\nInstitutional email address (Gmail, Hotmail, etc are not accepted)\nMobile phone number (optional, but strongly encouraged as you otherwise won’t be able to easily reset your password)\nEither:\n\nNCI project code of an existing project you wish to join\nA new project proposal to be assessed by a Scheme Manager to determine if they will grant your project time\n\n\n\nNote that resources at NCI are allocated to projects and not to individual users.\n\n\n\nClick on the Sign up here link to start your registration form.\n\n\nComplete all steps in the registration form.\n\n\n\n\nYour username will become active when a project Lead CI approves your request to join their project, or when a Scheme Manager approves your new project proposal. You will receive a confirmation email from the Mancini system when your username is activated."
  },
  {
    "objectID": "notebooks/hpc.html#how-to-log-into-gadi",
    "href": "notebooks/hpc.html#how-to-log-into-gadi",
    "title": "Accessing NCI Gadi HPC",
    "section": "How to log into Gadi",
    "text": "How to log into Gadi\n\nLinux/Mac/Unix\nAccess to Gadi is via SSH to gadi.nci.org.au. This provides a Unix shell on one of the Gadi login nodes.\n\n\n\nReplace abc123 with your own username. Enter your password when prompted. If you can’t remember your password, you can reset it via Mancini.\n\n\n\nCopying Files\nTo copy files to Gadi you should use the Gadi data movers gadi-dm.nci.org.au:\n\n\n\n\nX11 (X-Windows)\n\n\n\nWhen using OS X 10.8 or later you will need to install XQuartz from https://www.xquartz.org before you can use X11 on a Mac.\n\n\n\nCopying Files\nWe recommend the use of one of the following packages for X11 access to Gadi:\n\n\nMobaXterm from http://mobaxterm.mobatek.net\nCygwin from https://cygwin.com\nXming from http://www.straightrunning.com/XmingNotes/\n\n\n\n\n\nWindows\n\n\n\n\n\nCopying Files\nTo copy files to Gadi you should use the Gadi data movers gadi-dm.nci.org.au:\nWe recommend the following applications to copy files to and from Gadi:\n\n\nMobaXterm from http://mobaxterm.mobatek.net\nPuTTY’s PSCP or PSFTP applications from http://www.chiark.greenend.org.uk/~sgtatham/putty/\nFileZilla from https://filezilla-project.org\nWinSCP from https://winscp.net/\n\n\nTo transfer files/folders using MobaXterm on Windows system, drag and drop files/folders to/from local computer and Gadi after log in to Gadi via MobaXterm."
  },
  {
    "objectID": "notebooks/hpc.html#set-up-your-nci-account",
    "href": "notebooks/hpc.html#set-up-your-nci-account",
    "title": "Accessing NCI Gadi HPC",
    "section": "Set up your NCI Account",
    "text": "Set up your NCI Account\nAll new users must create their account through the NCI online self service portal. To create your account you will need the following information:\n\nYour Name\nInstitutional email address (Gmail, Hotmail, etc. are not accepted)\nMobile phone number\nEither:\n\nNCI project code of an existing project you wish to join\nA new project proposal to be assessed by a Scheme Manager to determine if they will grant your project time\n\n\nNote that resources at NCI are allocated to projects and not to individual users.\nComplete all steps below to set up an NCI account:\n\nClick on ‘Sign up’ link on the NCI online self service portal: \nAccept the terms and conditions: \nProvide your personal details: \nProvide details on the project you’ll be working on: \nSelect University of Sydney as you institution: \n\nYour username will become active when a project Lead CI approves your request to join their project, or when a Scheme Manager approves your new project proposal. You will receive a confirmation email from the Mancini system when your username is activated."
  },
  {
    "objectID": "notebooks/hpc.html#log-into-gadi",
    "href": "notebooks/hpc.html#log-into-gadi",
    "title": "Accessing NCI Gadi HPC",
    "section": "Log into Gadi",
    "text": "Log into Gadi\nAccess to Gadi is via SSH to gadi.nci.org.au. This provides a Unix shell on one of the Gadi login nodes.\nOpen a terminal application and type the following command:\nssh abc123@gadi.nci.org.au \nReplace abc123 with your own username. Enter your password when prompted. If you can’t remember your password, you can reset it via Mancini. Navigate to your project space:\ncd /scratch/ab01\nReplace ab01 with your project name.\n\nCopy your data from RDS to Gadi\nTo copy files to Gadi you should use the Gadi data mover queue gadi-dm.nci.org.au. To transfer data from USyd’s RDS you’ll need to set up ssh keys\n\n\n\nWindows\n\n\n\n\n\nCopying Files\nTo copy files to Gadi you should use the Gadi data movers gadi-dm.nci.org.au:\nWe recommend the following applications to copy files to and from Gadi:\n\n\nMobaXterm from http://mobaxterm.mobatek.net\nPuTTY’s PSCP or PSFTP applications from http://www.chiark.greenend.org.uk/~sgtatham/putty/\nFileZilla from https://filezilla-project.org\nWinSCP from https://winscp.net/\n\n\nTo transfer files/folders using MobaXterm on Windows system, drag and drop files/folders to/from local computer and Gadi after log in to Gadi via MobaXterm."
  },
  {
    "objectID": "notebooks/hpc.html#get-a-terminal",
    "href": "notebooks/hpc.html#get-a-terminal",
    "title": "Accessing NCI Gadi HPC",
    "section": "Get a terminal",
    "text": "Get a terminal\nOnce you have been granted access to NCI you are able to access the platform. To do this, you will need to download a terminal application on your local computer or via NCI’s Australian Research Environment platform (ARE).\nOften just called a ‘terminal’, or ‘shell terminal’, ‘shell client’, terminal emulators give you a window with a command line interface through which you can send commands to be executed by your computer.\n\nLinux\nIf you use Linux, then chances are you already know your shell and how to use it. Basically, just open your preferred terminal program and off you go! An X-Window server (X11) may also be useful if you want to be able to use GUIs; again, if you’re using Linux you probably have one, and if you don’t have one, it’s probably because you intentionally disabled it!\n\n\nMac\nMac operating systems come with a terminal program, called Terminal. Just look for it in your Applications folder, or hit Command-Space and type ‘terminal’.\n\n\nWindows\nYou’ll need extra programs and utilities to connect to HPCs like Gadi and Artemis, such as an SSH implementation. To access Gadi on Windows, you have a couple of options:\n\nMobaXterm from http://mobaxterm.mobatek.net\nPuTTY from https://putty.org/\n\nAccess to Gadi is via SSH to gadi.nci.org.au. This provides a Unix shell on one of the Gadi login nodes.\n\n\n\nReplace abc123 with your own username. Enter your password when prompted. If you can’t remember your password, you can reset it via Mancini.\n\n\n\n\nCopying Files\nTo copy files to Gadi you should use the Gadi data movers gadi-dm.nci.org.au:\n\n\n\nWindows\n\n\n\n\n\nCopying Files\nTo copy files to Gadi you should use the Gadi data movers gadi-dm.nci.org.au:\nWe recommend the following applications to copy files to and from Gadi:\n\n\nMobaXterm from http://mobaxterm.mobatek.net\nPuTTY’s PSCP or PSFTP applications from http://www.chiark.greenend.org.uk/~sgtatham/putty/\nFileZilla from https://filezilla-project.org\nWinSCP from https://winscp.net/\n\n\nTo transfer files/folders using MobaXterm on Windows system, drag and drop files/folders to/from local computer and Gadi after log in to Gadi via MobaXterm."
  },
  {
    "objectID": "notebooks/hpc.html#using-a-terminal-application",
    "href": "notebooks/hpc.html#using-a-terminal-application",
    "title": "Accessing NCI Gadi HPC",
    "section": "Using a terminal application",
    "text": "Using a terminal application\nOnce you have been granted access to NCI you are able to access the platform. To do this, you will need to download a terminal application on your local computer or via NCI’s Australian Research Environment platform (ARE).\nIf you don’t have a terminal already or know what one is, it is used to provide a window with a command line interface through which you can send commands to be executed by the HPC remotely or your local machine. See here for instructions on downloading a terminal application for your computer.\n\nLog into Gadi\nYou will need to access the Gadi HPC via the command line when using the Nextflow Tower service for a few purposes:\n\nTo transfer data to and from the University of Sydney’s research data store\nTo turn on the Tower Agent before running a workflow\n\nAccess to Gadi is via SSH to gadi.nci.org.au. This provides a Unix shell on one of the Gadi login nodes.\nOpen a terminal application and type the following command:\nssh abc123@gadi.nci.org.au \nReplace abc123 with your own username. Enter your password when prompted. If you can’t remember your password, you can reset it via Mancini. Navigate to your project space:\ncd /scratch/ab01\nReplace ab01 with your project name.\n\n\nTransfer your data to and from Gadi\nTo copy files to Gadi you should use the Gadi data mover queue and gadi-dm.nci.org.au. To transfer data from USyd’s RDS via a PBS job, you’ll need to set up ssh keys for passwordless transfer of datasets using the University of Sydney’s Artemis HPC.\n\nSet up ssh keys\n1. Generate SSH Key Pair on the Artemis HPC\nLog in to the Artemis HPC and stay in your home directory:\nssh unikey@hpc.sydney.edu.au\nRun the following command to generate an SSH key pair without a passphrase:\nssh-keygen -t rsa -b 2048 -N \"\"\nPress enter when prompted, saving the key in ~/.ssh/id_rsa.\n2. Set Appropriate Permissions\nEnsure that your SSH key files have the appropriate permissions to maintain a secure environment:\nSet permissions on your SSH key files using chmod command:\nchmod 700 ~/.ssh\nchmod 600 ~/.ssh/id_rsa\nchmod 644 ~/.ssh/id_rsa.pub\nCreate the authorized_keys file to transfer to Gadi HPC:\ncat ~/.ssh/id_rsa.pub >> ~/authorized_keys\nThen set permissions on this file with chmod:\nchmod 700 ~/authorized_keys\n3. Transfer Public Key to Gadi\nNow move your authorized_keys file to Gadi HPC. Start by logging into Gadi from the Artemis HPC CLI and provide your password when prompted:\nsftp abc123@gadi-dm.nci.org.au\nReplace abc123 above with your NCI username.\nIf you don’t already have an .ssh directory in your home directory, you’ll need to create one:\nmkdir ~/.ssh \nMove into the .ssh directory and transfer your authorized_keys file:\ncd ~/.ssh\nput authorized_keys\nThis will transfer authorized_keys on Gadi to your current directory. With sftp, it will look for the file relative to where you launched sftp. You can check where you are on Artemis using lls.\n4. Set Up the Public Key on the Gadi HPC\nLog in to the Gadi HPC via the data mover address:\nssh abc123@gadi-dm.nci.org.au\nAppend the transferred public key to the ~/.ssh/authorized_keys file using the following command:\ncat /path/to/directory/id_rsa.pub >> ~/.ssh/authorized_keys\n\nSet appropriate permissions for the ~/.ssh/authorized_keys file:\nchmod 600 ~/.ssh/authorized_keys\n\n5. Test the setup\nLogout using ctrl+z and test the sftp connection. You should not need to use a password:\nsftp abc123@gadi-dm.nci.org.au\nThis completes the setup. Now you can log in to the Gadi HPC from the Artemis HPC without entering a password each time. Be sure to handle your private key securely, especially since it is not passphrase protected.\n\n\nCopying files from RDS to Gadi\nUsing a PBS job to transfer data transfer between Artemis HPC and NCI’s Gadi HPC using scp or rsync is a good practice. Below is a simple example of a PBS script that you might run from Artemis to transfer data to Gadi HPC:\n#!/bin/bash\n\n# Transfer files from Gadi to RDS by submitting this job on Artemis\n# Must have ssh-keys set up for passwordless transfer\n\n#PBS -P SIH\n#PBS -N transfer\n#PBS -l walltime=24:00:00\n#PBS -l ncpus=1\n#PBS -l mem=40GB\n#PBS -W umask=022\n#PBS -q dtq\n\nnci_username= #specify your nci username\nsource_host=${nci_username}@gadi-dm.nci.org.au\nsource_path= #specify path to data to be transferred\ndestination_path=/rds/PRJ-SIH/FromGadi #specify path of where you'd like to upload data\n\nwhile [ 1 ]\ndo\n  echo Transferring ${source_host}:${source_path}/${dir} to ${destination_path}\n  rsync -rPvz -L --append-verify ${source_host}:${source_path}/${dir} ${destination_path}\n\ndone"
  },
  {
    "objectID": "notebooks/workflow.html",
    "href": "notebooks/workflow.html",
    "title": "Running Workflows on HPC",
    "section": "",
    "text": "Before you can execute workflows on Tower on Gadi, you will first need to run the tower agent. Navigate to the previously set up tower-nf directory on the command line and run the agent: \n\n\ncd /scratch/iz89/tower-nf \nbash run_tower_agent_pbs.sh\n\n\nBack at the tower interface, navigate to your launchpad or run on the command line and monitor on Tower:"
  },
  {
    "objectID": "notebooks/workflow.html#pawsey-setonix",
    "href": "notebooks/workflow.html#pawsey-setonix",
    "title": "Running Workflows on HPC",
    "section": "Pawsey Setonix",
    "text": "Pawsey Setonix\nBefore you can execute workflows on Tower on Setonix, you will first need to run the tower agent.  Navigate to the previously set up tower-nf directory on the command line and run the agent: \n\n\ncd $MYSOFTWARE\nbash run_tower_agent_slurm.sh\n\n\nBack at the tower interface, navigate to your launchpad."
  },
  {
    "objectID": "notebooks/setup_admin.html",
    "href": "notebooks/setup_admin.html",
    "title": "Setup for the Admin Role",
    "section": "",
    "text": "You will need to create a Tower personal access token and store it on your compute environment (i.e. on the HPC environment, not locally) in order to communicate with the Tower API. To create a personal access token you will need to navigate to the user settings logo in the top navbar and select ‘Your tokens’, then:\n\nSelect ‘Add Token’. \nName your token something descriptive and select ‘Add’: \nCopy the token to your clipboard: \nOpen your terminal application, log in to your HPC (either NCI Gadi or Pawsey Setonix) on the command-line:\n\nssh abc123@gadi.nci.org.au\n\nIf you are using Gadi, navigate to ~ ($HOME):\n\ncd ~\n\nIf you are on Setonix, navigate to $MYSOFTWARE:\n\ncd $MYSOFTWARE\n\nFrom within the directory mentioned above, make a hidden tower (.tower) directory to store Tower token and credentials:\n\nmkdir .tower\n\nCopy your personal access token into a file named token within this directory:"
  },
  {
    "objectID": "notebooks/setup_admin.html#the-interface",
    "href": "notebooks/setup_admin.html#the-interface",
    "title": "Setup for the Admin Role",
    "section": "The interface",
    "text": "The interface\nUpon signing into Tower, you will be greeted with an interface for you as an individual user. To access the full functionality offered by the Australian BioCommons Tower service, you will need to move into (one of) your assigned BioCommons workspaces. To do this:\n\n\nSelect the dropdown menu by your user name.\nThen select the BioCommons workspace of interest.\n\n\nEach user has a unique personal workspace to manage resources such as pipelines, compute environments, and credentials. You can also create multiple workspaces within an organization context and associate each of these workspaces with dedicated teams of users, while providing a fine-grained access control model for each of the teams.\nThe Tower Dashboard provides an overview of runs in your organizations and personal workspace at a glance. Access it from the user top-right menu, under Dashboard. This is where you will manage your workspaces and workflows. It will open to the launchpad interface.\n\nAbove the interface you’ll see the following:\n\n\n\nLaunchpad: all your configured pipelines will be available here for running. Run them from here by selecting the ‘Launch’ button for the pipeline of interest. \nRuns: from here you can monitor and inspect the details of all previous workflow executions that you and other users in your workspace have run.\nActions: you can use Github and Tower webhooks to trigger an automated pipeline test run based on things like pipeline version release. \nDatasets: you can store pipeline input sample sheets here that specify metadata and file paths for each of your datapoints or samples to be processed by a workflow. \nCompute environment: Tower can be used to deploy workflows on various environments, here you will be able to manage and find your preconfigured environments. \nCredentials: here you can store all your authentication keys, credentials required to access private code repositories on GitHub, the Tower agent on HPCs, and external services. These are all encrypted, so they cannot be accessed by anyone else once you’ve stored them. \nSecrets: Ignore for now. \nParticipants: here you can see and manage (if you are an admin) the other users in your workspace and define user roles to control access. \nSettings: manage some basic workspace settings (if you are an admin)."
  },
  {
    "objectID": "notebooks/setup_admin.html#setting-up-your-workspace",
    "href": "notebooks/setup_admin.html#setting-up-your-workspace",
    "title": "Setup for the Admin Role",
    "section": "Setting up your workspace",
    "text": "Setting up your workspace\nWorkspace configuration can only be performed by admins. With workspace configuration, you can create and configure compute environments, configure workflows to run on these environments, and add collaborators. The NeuroCommunity are currently only trialling the Tower service at NCI Gadi and Pawsey Setonix HPCs. As such, you will need to create Tower Agent credentials because this is the only way to access NCI and Pawsey HPC’s with Tower.\n\nCreate your personal access token\nYou will need to create a personal access token and store it on your compute environment (i.e. on the HPC environment, not locally) in order to communicate with the Tower API. To create a personal access token you will need to navigate to the user settings logo in the top navbar and select ‘Your tokens’, then:\n\n\nSelect ‘Add Token’. \nName your token something descriptive and select ‘Add’.\n\nCopy the token to your clipboard.\n\nLog in to your HPC (either NCI Gadi or Pawsey Setonix) on the command-line.\n\nIf you are using Gadi, navigate to $HOME.\nIf you are on Setonix, navigate to $MYSOFTWARE.\n\nFrom within the directory mentioned above, make a hidden directory called tower to store Tower token and credentials in.\nCopy your personal access token into a file named token within this directory.\n\n\n\n\n\nCreate a Tower credential for your HPC\nYou can create different types of credentials for different purposes through the Tower interface. For example, you can add credentials to access code repositories, commercial cloud, SSH-keys, and the Tower Agent. To connect your Tower agent to your HPC, you will need to create a Tower agent personal credential.\n\nTo set up your Tower agent credential, you will need to navigate to the user settings logo in the top navbar and select ‘Your credentials’.  \nYou can either choose to work with a shared or personal credential. Setting this up requires a similar process to creating a personal access token, using both the command line and Tower interface. Starting on the Tower interface, navigate to ‘Credentials’ in the top navbar menu:\n\n\n\nSelect ‘Add Credential’.\nName the credential something descriptive.\nSelect Tower Agent from the Provider dropdown menu.\nEnable ‘Shared agent’ so that all workspace users can access the same instance (optional).\nCopy the Agent connection ID to your clipboard.\n\nBefore saving the credential you will need to run the agent on your HPC command line. \nLog in to your HPC project space on the command-line and navigate to the shared space where you’ll be running the tower agent from. \nCopy your personal access token into a file named connection_id within the hidden .tower directory.\n\nNavigate to your working directory (not $HOME).\n\nOn gadi, run the run_tower_agent_pbs.sh script at /g/data/er01/tower-nf.\n\nOn setonix, TBA.\n\nBack in the tower interface, hit ‘Add’ to save your Tower agent credential.\nYou can cancel the Tower agent running on the command line after the credential is saved.\n\n\n\n\nConfigure a compute environment \nCompute environments have been configured for our group on NCI Gadi and Pawsey Setonix HPCs. The process for setting up this workspace is as follows:\n\n\nRun the tower agent on the HPC command line again with the relevant run_tower_agent_<pbs|slurm>.sh script\nIn the Tower interface, navigate to ‘Compute Environments’ in the top navbar menu.\nName the environment something descriptive to distinguish it from other environments you may set up.\nSelect the platform. For Setonix this is Slurm workload manager, for Gadi this is Altair PBS Pro. \nProvide your (shared or personal) credentials previously saved to the connection_id file.\n\n\n\n\nNCI Gadi HPC\nCurrently only NCI Gadi is a shared environment. The NCI Gadi environment has specifically been configured for our SIH project ‘er01’. Only users with access to er01 added to our workspace will be able to run workflows using this configured compute environment. It’s important that you leave the head and compute queue names empty, given jobs submitted to queues on Gadi are transferred to the exec version of each queue once running. The exec queue names are not visible to the Tower API so your jobs will fail to run. \n\n\nUnder Staging options:\n\nmodule load nextflow/23.04.1.\nmodule load singularity/3.8.6-nompi.\n\nUnder Advanced options:\n\nNextflow queue size: Set to 1000 (as directed here).\nHead job options: PBS options and applied head jobs to the compute jobs. Add queue as “copyq” to provide external network access.\n\n--Iwalltime=10:00:00, ncpus=1, mem=8G, storage=scratch/<project>+gdata/<project>, wd -P <project> -q copyq\n\n\n\n\n\n\n\nPawsey Setonix HPC\n\n\nWork directory: $TW_AGENT_WORK.\nLaunch directory: should be in the /scratch partition, because this is where you should run workflows. For example, /scratch/project_id/user_id/sv_calling.\nHead queue name: work.\nCompute queue name: work, unless you have a specific reason to select the long, highmem, or copy queue due to your workflow requirements.\nUnder Staging options:\n\nPre-run script: Here we load the needed system modules for running a Nextflow tower job. This currently includes the following modules, but the specific versions may change over time. You can check on the Setonix command line which module versions are available\n\nmodule load nextflow/23.04.1 \nmodule load singularity/3.8.6-nompi\n\n\nUnder Advanced options:\n\nNextflow queue size: Set to 1024.\nHead job submit options: This setting provides resources specifications for running the Nextflow head job. The main parameter you might want to change is `time`. You may need less than 24 hours walltime, in which case you can reduce the requested time.\n\n--time=24:00:00 --ntasks=1 --tasks-per-node=1 --mem=12G --cpus-per-task=1"
  },
  {
    "objectID": "notebooks/setup_admin.html#adding-collaborators",
    "href": "notebooks/setup_admin.html#adding-collaborators",
    "title": "Setup for the Admin Role",
    "section": "Adding collaborators",
    "text": "Adding collaborators\nCollaborators are users who are invited to an organizations workspace, but are not members of that organization. As a result, their access is limited to only within that workspace. New collaborators to an organization’s workspace can be added using the Participants.\n\nTo create a new team within an organization:\n\nGo to the Participants tab of the organization menu.\nClick on Add participant.\nEnter the Name of new participant. \nOptionally, update the role associated with the participant of the organization members or collaborators.\n\n\nThere are five roles available for every workspace participant:\n\n\nOwner: The participant have full permissions on any resources within the workspace, including the workspace settings.\nAdmin: The participant have full permission on the resources associated with the workspace. Therefore they can create/modify/delete Pipelines, Compute environments, Actions and Credentials. They can add/remove users to the workspace, but cannot access the workspace settings.\nMaintain: The participant can launch pipelines and modify pipeline executions (e.g. can change the pipeline launch compute environments, parameters, pre/post-run scripts and nextflow configuration) and create new pipelines in the Launchpad. The users cannot modify Compute Environments and Credentials.\nLaunch: The participant can launch pipelines and modify the pipeline input/output parameters in the Launchpad. They cannot modify the launch configuration and other resources.\nView: The participant can view the team pipelines and runs in read-only mode."
  },
  {
    "objectID": "notebooks/setup_admin.html#logging-into-the-service",
    "href": "notebooks/setup_admin.html#logging-into-the-service",
    "title": "Setup for the Admin Role",
    "section": "Logging into the service",
    "text": "Logging into the service\nRather than the more common username and password style login you might be used to, NextFlow Tower uses an authentication link. To login:\n\n\n\nGo to https://tower.services.biocommons.org.au.\nProvide your University email address. ou will then receive an email with the access link in your email inbox. Click on this link to be logged into Nextflow Tower. Note that it can take a few minutes for the link to hit your inbox."
  },
  {
    "objectID": "notebooks/curation.html",
    "href": "notebooks/curation.html",
    "title": "Workspace management and use",
    "section": "",
    "text": "Any Australian researcher can access the Australian BioCommons Tower Service during the pilot phase and use their own personal workspace. Once you’ve set up your compute access and been added to a Nextflow Tower workspace, you’ll be able to do the following, depending on your assigned role:"
  },
  {
    "objectID": "notebooks/curation.html#logging-into-the-service",
    "href": "notebooks/curation.html#logging-into-the-service",
    "title": "Workspace management and use",
    "section": "Logging into the service",
    "text": "Logging into the service\nRather than the more common username and password style login you might be used to, NextFlow Tower uses an authentication link. To login:\nGo to https://tower.services.biocommons.org.au.\nProvide your University email address. ou will then receive an email with the access link in your email inbox. Click on this link to be logged into Nextflow Tower. Note that it can take a few minutes for the link to hit your inbox."
  },
  {
    "objectID": "notebooks/curation.html#using-the-interface",
    "href": "notebooks/curation.html#using-the-interface",
    "title": "Workspace management and use",
    "section": "Using the interface",
    "text": "Using the interface\nUpon signing into Tower, you will be greeted with an interface for you as an individual user. To access the full functionality offered by the Australian BioCommons Tower service, you will need to move into (one of) your assigned BioCommons workspaces. To do this:\n\nSelect the dropdown menu by your user name.\nThen select the BioCommons workspace of interest.\n\nEach user has a unique personal workspace to manage resources such as pipelines, compute environments, and credentials. You can also create multiple workspaces within an organisation context and associate each of these workspaces with dedicated teams of users, while providing a fine-grained access control model for each of the teams.\nThe Tower Dashboard provides an overview of runs in your organisations and personal workspace at a glance. Access it from the user top-right menu, under Dashboard. This is where you will manage your workspaces and workflows. It will open to the launchpad interface.\n\nAbove the interface you’ll see the following:\n\nLaunchpad: all your configured pipelines will be available here for running. Run them from here by selecting the ‘Launch’ button for the pipeline of interest. \nRuns: from here you can monitor and inspect the details of all previous workflow executions that you and other users in your workspace have run.\nActions: you can use Github and Tower webhooks to trigger an automated pipeline test run based on things like pipeline version release. \nDatasets: you can store pipeline input sample sheets here that specify metadata and file paths for each of your datapoints or samples to be processed by a workflow. \nCompute environment: Tower can be used to deploy workflows on various environments, here you will be able to manage and find your preconfigured environments. \nCredentials: here you can store all your authentication keys, credentials required to access private code repositories on GitHub, the Tower agent on HPCs, and external services. These are all encrypted, so they cannot be accessed by anyone else once you’ve stored them. \nSecrets: Ignore for now. \nParticipants: here you can see and manage (if you are an admin) the other users in your workspace and define user roles to control access. \nSettings: manage some basic workspace settings (if you are an admin)."
  },
  {
    "objectID": "notebooks/curation.html#roles-and-resposibilities",
    "href": "notebooks/curation.html#roles-and-resposibilities",
    "title": "Workspace management and use",
    "section": "Roles and resposibilities",
    "text": "Roles and resposibilities"
  },
  {
    "objectID": "notebooks/curation.html#roles-and-responsibilities",
    "href": "notebooks/curation.html#roles-and-responsibilities",
    "title": "Workspace management and use",
    "section": "Roles and responsibilities",
    "text": "Roles and responsibilities\nDepending on how you will be using the Tower service, you may be provided with access limitations by the workspace administrator.\n\nAdmins are responsible for workspace curation, managing compute environments, and adding pipelines\nOther members are able to run workflows and won’t have the ability to add or remove compute environments, or pipelines.\n\nUSyd users are currently only trialing the Tower service at NCI Gadi and Pawsey Setonix HPCs. As such, all users will need to set up Tower Agent credentials before they can use the Tower service, as this is the only way to access NCI and Pawsey HPC’s with Nextflow Tower.\nSee the following sections for more details."
  },
  {
    "objectID": "notebooks/setup_admin.html#add-collaborators",
    "href": "notebooks/setup_admin.html#add-collaborators",
    "title": "Setup for the Admin Role",
    "section": "Add collaborators",
    "text": "Add collaborators\nCollaborators are users who are invited to an organizations workspace, but are not members of that organization. As a result, their access is limited to only within that workspace. New collaborators to an organization’s workspace can be added using the Participants.\nTo create a new team within a workspace:\n\nGo to the Participants tab of the top menu.\nClick on Add participant.\nEnter the Name of new participant. This person will have needed to log into tower before they can be added.\nOptionally, update the role associated with the participant of the organization members or collaborators.\n\nThere are five roles available for every workspace participant:\n\nOwner: The participant have full permissions on any resources within the workspace, including the workspace settings.\nAdmin: The participant have full permission on the resources associated with the workspace. Therefore they can create/modify/delete Pipelines, Compute environments, Actions and Credentials. They can add/remove users to the workspace, but cannot access the workspace settings.\nMaintain: The participant can launch pipelines and modify pipeline executions (e.g. can change the pipeline launch compute environments, parameters, pre/post-run scripts and nextflow configuration) and create new pipelines in the Launchpad. The users cannot modify Compute Environments and Credentials.\nLaunch: The participant can launch pipelines and modify the pipeline input/output parameters in the Launchpad. They cannot modify the launch configuration and other resources.\nView: The participant can view the team pipelines and runs in read-only mode."
  },
  {
    "objectID": "notebooks/setup_admin.html#set-up-your-groups-workspace",
    "href": "notebooks/setup_admin.html#set-up-your-groups-workspace",
    "title": "Setup for the Admin Role",
    "section": "Set up your group’s workspace",
    "text": "Set up your group’s workspace\nWorkspace configuration can only be performed by admins. With workspace configuration, you can create and configure compute environments, configure workflows to run on these environments, and add collaborators.\n\nCreate a Tower credential for your HPC\nYou can create different types of credentials for different purposes through the Tower interface. For example, you can add credentials to access code repositories, commercial cloud, SSH-keys, and the Tower Agent. To connect your Tower agent to your HPC, you will need to create a Tower agent personal credential.\nTo set up your Tower agent credential, you will need to navigate to the user settings logo in the top navbar and select ‘Your credentials’.\nYou can either choose to work with a shared or personal credential. Setting this up requires a similar process to creating a personal access token, using both the command line and Tower interface. Starting on the Tower interface, navigate to ‘Credentials’ in the top navbar menu:\n\nSelect ‘Add Credential’.\nName the credential something descriptive.\nSelect Tower Agent from the Provider dropdown menu.\nEnable ‘Shared agent’ so that all workspace users can access the same instance.\nCopy the Agent connection ID to your clipboard. \nBefore saving the credential you will need to run the agent on your HPC command line. \nLog in to your HPC project space (same as above) on the command-line and navigate to the shared space where you’ll be running the tower agent from and create another hidden .tower directory: \n\ncd /g/data/project-code/Tower_runs\nmkdir ./tower\n\nCopy your personal access token into a file named connection_id within the hidden .tower directory: \nNavigate to your Tower directory (not $HOME).\nDownload the Tower HPC helper scripts from github to this same space:\n\ngit clone https://github.com/Sydney-Informatics-Hub/tower-nf.git\n\nRun the relevant run_agent script to run the tower agent. This script will automatically find your personal access token and shared workspace credential:\n\nbash tower-nf/run_tower_agent_pbs.sh \n\n\nGo back in the tower interface in your web browser, hit ‘Add’ to save your Tower agent credential.\nThe tower agent has to run while you set up your workspaces or run a workflow. You can cancel the Tower agent running on the command line after the credential is saved using ctrl+C\n\n\n\nConfigure a compute environment \n\nRun the tower agent on the HPC command line again with the relevant run_tower_agent_<pbs|slurm>.sh script, same as above.\nIn the Tower interface, navigate to ‘Compute Environments’ in the top navbar menu.\nName the environment something descriptive to distinguish it from other environments you may set up.\nSelect the platform. For Setonix this is Slurm workload manager, for Gadi this is Altair PBS Pro. \nProvide your (shared or personal) credentials previously saved to the connection_id file. \n\nTo set up your NCI Gadi HPC compute environment:\n\nUnder Staging options add: module load singularity nextflow\nUnder Advanced options specify:\n\nNextflow queue size: 300 (as directed here)\nHead job options: --Iwalltime=10:00:00, ncpus=1, mem=8G, storage=scratch/\\<project\\>+gdata/\\<project\\>, wd -P \\<project\\> -q copyq\n\n\n\nNCI is currently working on solutions to improve the deployment of the Tower agent on Gadi. The above directions are subject to change. Currently, it is important that you leave the head and compute queue names empty, given jobs submitted to queues on Gadi are transferred to the exec version of each queue once running. The exec queue names are not visible to the Tower API so your jobs will fail to run. \nTo set up your Pawsey Setonix HPC compute environment:\n\nUnder Work directory add: \\$TW_AGENT_WORK\nThe Launch directory should be in the /scratch partition, because this is where you should run workflows. For example, /scratch/project_id/user_id/sv_calling.\nFor Head queue name specify: work.\nFor Compute queue name specify: work, unless you have a specific reason to select the long, highmem, or copy queue due to your workflow requirements.\nUnder Staging options:\n\nPre-run script: Here we load the needed system modules for running a Nextflow tower job. This currently includes the following modules, but the specific versions may change over time. You can check on the Setonix command line which module versions are available: module load nextflow/23.04.1 singularity/3.8.6-nompi\n\nUnder Advanced options:\n\nNextflow queue size: Set to 1024.\nHead job submit options: This setting provides resources specifications for running the Nextflow head job. The main parameter you might want to change is `time`. You may need less than 24 hours walltime, in which case you can reduce the requested time: --time=24:00:00 \\--ntasks=1 \\--tasks-per-node=1 \\--mem=12G \\--cpus-per-task=1"
  }
]